architecture: YOLOF
pretrain_weights: pretrain/resnet50_va_pretrained.pdparams

#### Model ####

YOLOF:
  backbone: ResNet
  neck: DilatedEncoder
  head: YOLOFHead

ResNet:
  depth: 50
  variant: a
  norm_type: bn
  freeze_at: 0
  return_idx: [3]
  num_stages: 4
  lr_mult_list: [0.3333, 0.3333, 0.3333, 0.3333]

DilatedEncoder:
  in_channels: 2048
  out_channels: 512
  block_mid_channels: 128
  num_residual_blocks: 4

YOLOFHead:
  num_classes: 80
  prior_prob: 0.01
  nms_pre: 1000
  conv_feat:
    name: YOLOFFeat
    feat_in: 512
    feat_out: 512
    num_cls_convs: 2
    num_reg_convs: 4
    norm_type: bn
  anchor_generator:
    name: AnchorGenerator
    anchor_sizes: [[32, 64, 128, 256, 512]]
    aspect_ratios: [1.0]
    strides: [32]
  bbox_assigner:
    name: UniformAssigner
    pos_ignore_thr: 0.15
    neg_ignore_thr: 0.7
    match_times: 4
  bbox_coder:
    name: DeltaBBoxCoder
    delta_mean: [0.0, 0.0, 0.0, 0.0]
    delta_std: [1.0, 1.0, 1.0, 1.0]
    add_ctr_clip: true
    ctr_clip: 32
  loss_class:
    name: FocalLoss
    gamma: 2.0
    alpha: 0.25
    loss_weight: 1.0
  loss_bbox:
    name: GIoULoss
    loss_weight: 1.0
  nms:
    name: MultiClassNMS
    nms_top_k: 1000
    keep_top_k: 100
    score_threshold: 0.05
    nms_threshold: 0.6


#### Dataset ####

metric: COCO
num_classes: 80

TrainDataset:
  !COCODataSet
    image_dir: train2017
    anno_path: annotations/instances_train2017.json
    dataset_dir: dataset/coco
    data_fields: ['image', 'gt_bbox', 'gt_class']

EvalDataset:
  !COCODataSet
    image_dir: val2017
    anno_path: annotations/instances_val2017.json
    dataset_dir: dataset/coco

TestDataset:
  !ImageFolder
    anno_path: annotations/instances_val2017.json


#### Reader ####

worker_num: 8
TrainReader:
  sample_transforms:
  - Decode: {}
  - RGB2BGR: {}
  - RandomFlip: {prob: 0.5}
  - RandomShift: {prob: 0.5, max_shift: 32}
  - Resize: {target_size: [800, 1333], keep_ratio: true, interp: 1}
  - NormalizeImage: {is_scale: false, mean: [103.530, 116.280, 123.675], std: [1.0, 1.0, 1.0]}
  - Permute: {}
  batch_transforms:
  - PadBatch: {pad_to_stride: 32}
  batch_size: 8
  shuffle: true
  drop_last: true
  use_process: true
  collate_batch: false


EvalReader:
  sample_transforms:
  - Decode: {}
  - RGB2BGR: {}
  - Resize: {target_size: [800, 1333], keep_ratio: true, interp: 1}
  - NormalizeImage: {is_scale: false, mean: [103.530, 116.280, 123.675], std: [1.0, 1.0, 1.0]}
  - Permute: {}
  batch_transforms:
  - PadBatch: {pad_to_stride: 32}
  batch_size: 2
  shuffle: false


TestReader:
  sample_transforms:
  - Decode: {}
  - RGB2BGR: {}
  - Resize: {target_size: [800, 1333], keep_ratio: true, interp: 1}
  - NormalizeImage: {is_scale: false, mean: [103.530, 116.280, 123.675], std: [1.0, 1.0, 1.0]}
  - Permute: {}
  batch_transforms:
  - PadBatch: {pad_to_stride: 32}
  batch_size: 1
  shuffle: false



#### Optimizer ####

epoch: 12

LearningRate:
  base_lr: 0.06
  schedulers:
  - !PiecewiseDecay
    gamma: 0.1
    milestones: [8, 11]
  - !LinearWarmup
    start_factor: 0.00066
    steps: 1500

OptimizerBuilder:
  optimizer:
    momentum: 0.9
    type: Momentum
  regularizer:
    factor: 0.0001
    type: L2


#### Runtime ####

use_gpu: true
log_iter: 50
save_dir: output
snapshot_epoch: 1
print_flops: false




find_unused_parameters: True
